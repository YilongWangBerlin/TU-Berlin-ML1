{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Support Vector Machines\n",
    "\n",
    "In this exercise sheet, we will implement a kernel SVM. Our implementation will be based on a generic quadratic programming optimizer provided in CVXOPT (`python-cvxopt` package, or directly from the website `www.cvxopt.org`). The SVM will then be tested on the UCI breast cancer dataset, a simple binary classification dataset accessible via the `scikit-learn` library.\n",
    "\n",
    "## 1. Building the Gaussian Kernel (5 P)\n",
    "\n",
    "As a starting point, we would like to implement the Gaussian kernel, which we will make use of in our kernel SVM implementation. It is defined as:\n",
    "$$\n",
    "k(x,x') = \\exp \\Big( -\\frac{\\|x-x'\\|^2}{2 \\sigma^2} \\Big)\n",
    "$$\n",
    "\n",
    "* **Implement a function `getGaussianKernel` that returns for a Gaussian kernel of scale $\\sigma$, the Gram matrix of the two data sets given as argument.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:14:31.115621Z",
     "iopub.status.busy": "2024-11-19T11:14:31.115277Z",
     "iopub.status.idle": "2024-11-19T11:14:31.478026Z",
     "shell.execute_reply": "2024-11-19T11:14:31.477520Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy,scipy,scipy.spatial\n",
    "\n",
    "def getGaussianKernel(X1,X2,scale):\n",
    "    ### TODO: REPLACE BY YOUR OWN CODE\n",
    "    #import solutions\n",
    "    #K = solutions.getGaussianKernel(X1,X2,scale)\n",
    "    #return K\n",
    "    \n",
    "    #print(\"x:\",X1.shape)\n",
    "    #x: (284, 30)\n",
    "\n",
    "    \n",
    "    #K = numpy.exp(- (numpy.linalg.norm(X1 - X2) ** 2) / (2 * scale ** 2))\n",
    "    \n",
    "    K = numpy.zeros((X1.shape[0], X2.shape[0]))\n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X2.shape[0]):\n",
    "            K[i, j] = numpy.exp(- (numpy.linalg.norm(X1[i,:] - X2[j,:]) ** 2) / (2 * (scale ** 2)))\n",
    "            \n",
    "            \n",
    "    return K\n",
    "    ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the Matrices for the CVXOPT Quadratic Solver (20 P)\n",
    "\n",
    "We would like to learn a nonlinear SVM by optimizing its dual. An advantage of the dual SVM compared to the primal SVM is that it allows to use nonlinear kernels such as the Gaussian kernel. The dual SVM consists of solving the following quadratic program:\n",
    "\n",
    "$$\n",
    "\\max_\\alpha \\sum_{i=1}^N \\alpha_i - \\frac12 \\sum_{ij} \\alpha_i \\alpha_j y_i y_j k(x_i,x_j)\n",
    "\\qquad \n",
    "\\text{subject to:}\n",
    "\\qquad 0 \\leq \\alpha_i \\leq C \\qquad \\text{and} \\qquad \\sum_{i=1}^N \\alpha_i y_i = 0.\n",
    "$$\n",
    "\n",
    "We would like to rely on a CVXOPT solver to obtain a solution to our SVM dual. The function `cvxopt.solvers.qp` solves an optimization problem of the type:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{\\boldsymbol{x}} \\quad &\\frac12 \\boldsymbol{x}^\\top P \\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x}\\\\\n",
    "\\text{subject to} \\quad & G \\boldsymbol{x} \\preceq \\boldsymbol{h}\\\\\n",
    "\\text{and} \\quad & A \\boldsymbol{x} = \\boldsymbol{b}.\n",
    "\\end{align*}\n",
    "\n",
    "which is of similar form to our dual SVM (note that $\\boldsymbol{x}$ will correspond to the parameters $(\\alpha_i)_i$ of the SVM). We need to build the data structures (vectors and matrices) that makes solving this quadratic problem equivalent to solving our dual SVM.\n",
    "\n",
    "* **Implement a function `getQPMatrices` that builds the matrices `P`, `q`, `G`, `h`, `A`, `b` (of type `cvxopt.matrix`) that need to be passed as argument to the optimizer `cvxopt.solvers.qp`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:14:31.480517Z",
     "iopub.status.busy": "2024-11-19T11:14:31.480396Z",
     "iopub.status.idle": "2024-11-19T11:14:31.495245Z",
     "shell.execute_reply": "2024-11-19T11:14:31.494720Z"
    }
   },
   "outputs": [],
   "source": [
    "import cvxopt,cvxopt.solvers \n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "def getQPMatrices(K,T,C):\n",
    "    ### TODO: REPLACE BY YOUR CODE\n",
    "    #import solutions\n",
    "    #P,q,G,h,A,b = solutions.getQPMatrices(K,T,C)\n",
    "    #return P,q,G,h,A,b\n",
    "    \n",
    "    # T is the label y\n",
    "    N = len(T)\n",
    "    #print(\"K,T,C,N:\",K.shape,T.shape,C,N)\n",
    "    #K,T,C,N: (284, 284) (284,) 10 284\n",
    "\n",
    "    Y = T\n",
    "    \n",
    "    #P = T * T @ K\n",
    "    #print(    numpy.outer(T, T).shape,K.shape)\n",
    "    #print(\"Y[None],Y[:,None],K:\",Y[None].shape,Y[:,None].shape,K.shape)\n",
    "    #P = numpy.outer(Y, Y).dot(K)\n",
    "    #print(\"T:\",T.shape)\n",
    "    #print(\"outer:\",numpy.outer(Y, Y))\n",
    "    #print(\"Y[:,None] @ Y[None]:\",Y[:,None] @ Y[None])\n",
    "    \n",
    "    \n",
    "    P =  (Y[:,None] @ Y[None]) * K\n",
    "    q = -1 * numpy.ones((N,1))\n",
    "    G = numpy.vstack((-1*numpy.eye(N),numpy.eye(N)))\n",
    "    h = numpy.hstack((numpy.zeros(N),C * numpy.ones(N)))\n",
    "    A = T[None,:]\n",
    "    b = 0\n",
    "    \n",
    "    #print(P.shape,q.shape,G.shape,h.shape,A.shape,b)\n",
    "    #(284, 284) (284, 1) (568, 284) (568,) (1, 284) 0.0\n",
    "\n",
    "\n",
    "    \n",
    "    P = cvxopt.matrix(P, tc='d')\n",
    "    q = cvxopt.matrix(q, tc='d')\n",
    "    G = cvxopt.matrix(G, tc='d')\n",
    "    h = cvxopt.matrix(h, tc='d')\n",
    "    A = cvxopt.matrix(A, tc='d')\n",
    "    b = cvxopt.matrix(b, tc='d')\n",
    "\n",
    "\n",
    "    \n",
    "    return P,q,G,h,A,b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##dddsâ€ #\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computing the Bias Parameters (10 P)\n",
    "\n",
    "Given the parameters $(\\alpha_i)_i$ the optimization procedure has found, the prediction of the SVM is given by:\n",
    "\n",
    "$$\n",
    "f(x) = \\text{sign}\\Big(\\sum_{i=1}^N \\alpha_i y_i k(x,x_i) + \\theta\\Big)\n",
    "$$\n",
    "\n",
    "Note that the parameter $\\theta$ has not been computed yet. It can be obtained from any support vector that lies exactly on the margin, or equivalently, whose associated parameter $\\alpha$ is not equal to $0$ or $C$. Calling one such vector \"$x_M$\", the parameter $\\theta$ can be computed as:\n",
    "\n",
    "$$\n",
    "\\theta =  y_M - \\sum_{j=1}^N \\alpha_j y_j k(x_M,x_j) \n",
    "$$\n",
    "\n",
    "* **Implement a function `getTheta` that takes as input the Gram Matrix used for training, the label vector, the solution of our quadratic program, and the hyperparameter C. The function should return the parameter $\\theta$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:14:31.497456Z",
     "iopub.status.busy": "2024-11-19T11:14:31.497349Z",
     "iopub.status.idle": "2024-11-19T11:14:31.499274Z",
     "shell.execute_reply": "2024-11-19T11:14:31.498811Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTheta(K,T,alpha,C):\n",
    "    ### TODO: REPLACE BY YOUR CODE\n",
    "    #import solutions\n",
    "    #theta = solutions.getTheta(K,T,alpha,C)\n",
    "    #print(K.shape,T.shape,alpha)\n",
    "    #(284, 284) (284,) {'x': <284x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <568x1 matrix, tc='d'>, 'z': <568x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 7.118147899470116e-05, 'relative gap': 6.783961494705319e-07, 'primal objective': -104.92612472853241, 'dual objective': -104.9261959100114, 'primal infeasibility': 1.5101568542741277e-14, 'dual infeasibility': 5.925681618886442e-16, 'primal slack': 7.020236463770086e-08, 'dual slack': 6.403597588856221e-09, 'iterations': 9}\n",
    "\n",
    "    \n",
    "    alpha = numpy.array(alpha['x'])\n",
    "    #print(alpha.shape) \n",
    "    #(284, 1)\n",
    "    alpha = alpha.flatten()\n",
    "    #print(alpha) \n",
    "    \"\"\"\n",
    "    [5.92118709e+00 2.56049320e-07 3.11798719e-07 3.16622871e-07\n",
    " 1.08017991e+00 1.42118448e-07 7.80501476e-01 2.62696768e-07\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    idx = -1\n",
    "    for i in range(len(alpha)):\n",
    "        if 1e-6 < alpha[i] < C:\n",
    "            idx = i\n",
    "            break\n",
    "\n",
    "\n",
    "    y_M = T[idx]\n",
    "    theta = y_M - numpy.sum(alpha * T * K[idx,:])\n",
    "    \n",
    "    \n",
    "    return theta\n",
    "    ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing a class `GaussianSVM` (15 P)\n",
    "\n",
    "All functions that are needed to learn the SVM have now been built. We would like to implement a SVM class that connects them and make the SVM easily usable. The class structure is given below and contains two functions, one for training the model, and one for applying it to test data.\n",
    "\n",
    "* **Implement the function `fit` that makes use of the functions `getGaussianKernel`, `getQPMatrices`, `getTheta` you have already implemented. The function should learn the SVM model and store the support vectors, their label, $(\\alpha_i)_i$ and $\\theta$ into the object (`self`).**\n",
    "* **Implement the function `predict` that makes use of the stored information to compute the SVM output for any new collection of data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:14:31.501350Z",
     "iopub.status.busy": "2024-11-19T11:14:31.501245Z",
     "iopub.status.idle": "2024-11-19T11:14:31.503457Z",
     "shell.execute_reply": "2024-11-19T11:14:31.503204Z"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianSVM:\n",
    "\n",
    "    def __init__(self,C=1.0,scale=1.0):\n",
    "        \n",
    "        self.C , self.scale = C, scale\n",
    "    \n",
    "    def fit(self,X,T):\n",
    "\n",
    "        ### TODO: REPLACE BY YOUR CODE\n",
    "        #import solutions\n",
    "        #solutions.fit(self,X,T)\n",
    "        self.Y = T\n",
    "        K = getGaussianKernel(X,X,self.scale)\n",
    "        P,q,G,h,A,b = getQPMatrices(K,T,self.C)\n",
    "        alpha = cvxopt.solvers.qp(P,q,G,h,A,b)\n",
    "        self.alpha = numpy.array(alpha['x']).flatten()\n",
    "        self.theta = getTheta(K,T,alpha,self.C)\n",
    "        #print(self.alpha)\n",
    "        \n",
    "        sv_idx = numpy.logical_not(\n",
    "            numpy.isclose(numpy.zeros(self.alpha.shape[0]), self.alpha, atol=1e-5)\n",
    "        ) \n",
    "        '''\n",
    "        \n",
    "        for i in range(len(self.alpha)):\n",
    "            if 1e-6 < self.alpha[i] < self.C:\n",
    "                sv_idx.append(i)\n",
    "                \n",
    "        we dont need that because 0 < alpha < c has already in cvxopt \n",
    "        '''\n",
    "        \n",
    "                \n",
    "        self.sv_idx = sv_idx \n",
    "        self.X = X[sv_idx] # it's sv\n",
    "     \n",
    "        ###\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \n",
    "        ### TODO: REPLACE BY YOUR CODE\n",
    "        #import solutions\n",
    "        #Y = solutions.predict(self,X)\n",
    "        K = getGaussianKernel(self.X,X,self.scale)\n",
    "        #print(self.alpha.shape,self.Y.shape,K.shape) #(284,) (284,) (189, 284)\n",
    "        #print(X.shape) #(284, 30)\n",
    "        #print(\"self.sv_idx:\",len(self.sv_idx)) #self.sv_idx: 189\n",
    "        \n",
    "       # Y = numpy.sign((self.alpha[i] * self.Y[i] * K[Y[i],:]) for i in self.sv_idx)\n",
    "       # Y = numpy.sign(numpy.sum(self.alpha[i,None] * self.Y[i,None] * K[i, :] for i in self.sv_idx ) + self.theta)\n",
    "        #print(self.alpha[1,None].shape, self.Y[i,None].shape , K[1, :].shape)\n",
    "        alpha_sv = self.alpha[self.sv_idx]  \n",
    "        Y_sv = self.Y[self.sv_idx]\n",
    "        res = alpha_sv[:,None] * Y_sv[:,None] * K\n",
    "        #print(\"res:\",res.shape) #res: (189, 284)\n",
    "        #print(numpy.sum(res,axis=0).shape)\n",
    "        Y = numpy.sign(numpy.sum(res,axis=0) + self.theta)\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "        return Y\n",
    "        ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis\n",
    "\n",
    "The following code tests the SVM on some breast cancer binary classification dataset for a range of scale and soft-margin parameters. For each combination of parameters, we output the number of support vectors as well as the train and test accuracy averaged over a number of random train/test splits. Running the code below should take approximately 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=     30.0  C=     10.0  nSV:  168  train: 0.997  test: 0.921\n",
      "scale=     30.0  C=    100.0  nSV:  166  train: 1.000  test: 0.917\n",
      "scale=     30.0  C=   1000.0  nSV:  166  train: 1.000  test: 0.917\n",
      "scale=     30.0  C=  10000.0  nSV:  167  train: 1.000  test: 0.918\n",
      "\n",
      "scale=    100.0  C=     10.0  nSV:   94  train: 0.965  test: 0.932\n",
      "scale=    100.0  C=    100.0  nSV:   95  train: 0.987  test: 0.938\n",
      "scale=    100.0  C=   1000.0  nSV:   92  train: 0.997  test: 0.929\n",
      "scale=    100.0  C=  10000.0  nSV:   84  train: 0.965  test: 0.894\n",
      "\n",
      "scale=    300.0  C=     10.0  nSV:   69  train: 0.911  test: 0.896\n",
      "scale=    300.0  C=    100.0  nSV:   49  train: 0.946  test: 0.927\n",
      "scale=    300.0  C=   1000.0  nSV:   48  train: 0.944  test: 0.919\n",
      "scale=    300.0  C=  10000.0  nSV:   82  train: 0.891  test: 0.855\n",
      "\n",
      "scale=   1000.0  C=     10.0  nSV:   62  train: 0.901  test: 0.885\n",
      "scale=   1000.0  C=    100.0  nSV:   63  train: 0.898  test: 0.887\n",
      "scale=   1000.0  C=   1000.0  nSV:  132  train: 0.884  test: 0.876\n",
      "scale=   1000.0  C=  10000.0  nSV:  191  train: 0.852  test: 0.840\n",
      "\n",
      "scale=   3000.0  C=     10.0  nSV:   81  train: 0.877  test: 0.857\n",
      "scale=   3000.0  C=    100.0  nSV:   78  train: 0.892  test: 0.887\n",
      "scale=   3000.0  C=   1000.0  nSV:  149  train: 0.885  test: 0.874\n",
      "scale=   3000.0  C=  10000.0  nSV:  212  train: 0.867  test: 0.854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy,sklearn,sklearn.datasets,numpy\n",
    "\n",
    "D = sklearn.datasets.load_breast_cancer()\n",
    "X = D['data']\n",
    "T = D['target']\n",
    "T = (D['target']==1)*2.0-1.0\n",
    "\n",
    "for scale in [30,100,300,1000,3000]:\n",
    "    for C in [10,100,1000,10000]:\n",
    "        \n",
    "        acctrain,acctest,nbsvs = [],[],[]\n",
    "        \n",
    "        svm = GaussianSVM(C=C,scale=scale)\n",
    "        \n",
    "        for i in range(10):\n",
    "\n",
    "            # Split the data\n",
    "            R = numpy.random.mtrand.RandomState(i).permutation(len(X))\n",
    "            Xtrain,Xtest = X[R[:len(R)//2]]*1,X[R[len(R)//2:]]*1\n",
    "            Ttrain,Ttest = T[R[:len(R)//2]]*1,T[R[len(R)//2:]]*1\n",
    "\n",
    "            # Train and test the SVM\n",
    "            svm.fit(Xtrain,Ttrain)\n",
    "            acctrain += [(svm.predict(Xtrain)==Ttrain).mean()]\n",
    "            acctest  += [(svm.predict(Xtest)==Ttest).mean()]\n",
    "            nbsvs += [len(svm.X)*1.0]\n",
    "\n",
    "        print('scale=%9.1f  C=%9.1f  nSV: %4d  train: %.3f  test: %.3f'%(\n",
    "            scale,C,numpy.mean(nbsvs),numpy.mean(acctrain),numpy.mean(acctest)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:14:31.505576Z",
     "iopub.status.busy": "2024-11-19T11:14:31.505429Z",
     "iopub.status.idle": "2024-11-19T11:15:37.708930Z",
     "shell.execute_reply": "2024-11-19T11:15:37.708185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=     30.0  C=     10.0  nSV:  183  train: 0.997  test: 0.921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=     30.0  C=    100.0  nSV:  178  train: 1.000  test: 0.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=     30.0  C=   1000.0  nSV:  184  train: 1.000  test: 0.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=     30.0  C=  10000.0  nSV:  182  train: 1.000  test: 0.918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    100.0  C=     10.0  nSV:  117  train: 0.965  test: 0.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    100.0  C=    100.0  nSV:   97  train: 0.987  test: 0.940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    100.0  C=   1000.0  nSV:   85  train: 0.998  test: 0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    100.0  C=  10000.0  nSV:   71  train: 1.000  test: 0.926\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    300.0  C=     10.0  nSV:   88  train: 0.939  test: 0.924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    300.0  C=    100.0  nSV:   48  train: 0.963  test: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    300.0  C=   1000.0  nSV:   36  train: 0.978  test: 0.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=    300.0  C=  10000.0  nSV:   32  train: 0.991  test: 0.941\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   1000.0  C=     10.0  nSV:   66  train: 0.926  test: 0.916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   1000.0  C=    100.0  nSV:   55  train: 0.935  test: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   1000.0  C=   1000.0  nSV:   49  train: 0.956  test: 0.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   1000.0  C=  10000.0  nSV:   38  train: 0.971  test: 0.951\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   3000.0  C=     10.0  nSV:   87  train: 0.912  test: 0.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   3000.0  C=    100.0  nSV:   68  train: 0.926  test: 0.919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   3000.0  C=   1000.0  nSV:   58  train: 0.934  test: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale=   3000.0  C=  10000.0  nSV:   49  train: 0.953  test: 0.943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy,sklearn,sklearn.datasets,numpy\n",
    "\n",
    "D = sklearn.datasets.load_breast_cancer()\n",
    "X = D['data']\n",
    "T = D['target']\n",
    "T = (D['target']==1)*2.0-1.0\n",
    "\n",
    "for scale in [30,100,300,1000,3000]:\n",
    "    for C in [10,100,1000,10000]:\n",
    "        \n",
    "        acctrain,acctest,nbsvs = [],[],[]\n",
    "        \n",
    "        svm = GaussianSVM(C=C,scale=scale)\n",
    "        \n",
    "        for i in range(10):\n",
    "\n",
    "            # Split the data\n",
    "            R = numpy.random.mtrand.RandomState(i).permutation(len(X))\n",
    "            Xtrain,Xtest = X[R[:len(R)//2]]*1,X[R[len(R)//2:]]*1\n",
    "            Ttrain,Ttest = T[R[:len(R)//2]]*1,T[R[len(R)//2:]]*1\n",
    "\n",
    "            # Train and test the SVM\n",
    "            svm.fit(Xtrain,Ttrain)\n",
    "            acctrain += [(svm.predict(Xtrain)==Ttrain).mean()]\n",
    "            acctest  += [(svm.predict(Xtest)==Ttest).mean()]\n",
    "            nbsvs += [len(svm.X)*1.0]\n",
    "\n",
    "        print('scale=%9.1f  C=%9.1f  nSV: %4d  train: %.3f  test: %.3f'%(\n",
    "            scale,C,numpy.mean(nbsvs),numpy.mean(acctrain),numpy.mean(acctest)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the highest accuracy is obtained with a scale parameter that is neither too small nor too large. Best parameters are also often associated to a low number of support vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
